{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NNs (incomplete, intermediate).ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python [default]","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.6"}},"cells":[{"cell_type":"markdown","metadata":{"id":"SKEe7MzvveKD"},"source":["# Neural Networks: MNIST Handwritten Digit Classification "]},{"cell_type":"markdown","metadata":{"id":"LBjtJ6byveKF"},"source":["## Step 1: Load Data\n","\n","We'll be using the pre-labeled [**MNIST dataset**](https://en.wikipedia.org/wiki/MNIST_database), which contains 70,000 grayscale images of handwritten digits, along with their corresponding digit labels. \n","\n","Since we want our model to be able to perform well in the real world on **previously unseen data**, we'll only train it on 60,000 images, and then evaluate our model on the remaining 10,000."]},{"cell_type":"code","metadata":{"id":"-tdNnxIrveKF","nbpresent":{"id":"aa21eec0-d9e9-4575-8cec-408d8f044b20"},"executionInfo":{"status":"ok","timestamp":1601337682763,"user_tz":240,"elapsed":779,"user":{"displayName":"Philip Chang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEO7uNrPZ-ihF9DtyUuEYLoozRGFu5MCZrvu58=s64","userId":"11678586773252254122"}},"outputId":"5657afd3-9d6b-4897-fed2-b9d9a963fca0","colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# Giving Colab access to the drive like last time...we have to do this every time since we're using Colab\n","from google.colab import drive\n","drive.mount('/content/drive/')\n","%cd /content/drive/My Drive/CaisLessons/3: Neural Networks\n","\n","# Import MNIST Dataset from Keras\n","\n","from tensorflow.keras.datasets import mnist\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n","/content/drive/My Drive/CaisLessons/3: Neural Networks\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XDZx1YN5veKI","nbpresent":{"id":"b04508f5-7038-4d57-a3ad-a8e1dd3e172e"},"scrolled":true,"executionInfo":{"status":"ok","timestamp":1601338148002,"user_tz":240,"elapsed":525,"user":{"displayName":"Philip Chang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEO7uNrPZ-ihF9DtyUuEYLoozRGFu5MCZrvu58=s64","userId":"11678586773252254122"}},"outputId":"09bde969-1eb8-4ded-e5c3-1594c44877b6","colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["# Data Exploration (TODO: fill in the blanks)\n","# How many training and testing examples?\n","print(\"Number of training examples:\", len(X_train))\n","print(\"Number of testing examples:\", len(X_test))\n","\n","# What features are given for each example?\n","print(\"Shape of one example: \" + str(X_train[1].shape)) \n","\n","# What do our labels look like?\n","print(\"Labels: \", y_train)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Number of training examples: 60000\n","Number of testing examples: 10000\n","Shape of one example: (28, 28)\n","Labels:  [5 0 4 ... 5 6 8]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xjBCbG4KveKK","executionInfo":{"status":"ok","timestamp":1601338206518,"user_tz":240,"elapsed":551,"user":{"displayName":"Philip Chang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEO7uNrPZ-ihF9DtyUuEYLoozRGFu5MCZrvu58=s64","userId":"11678586773252254122"}},"outputId":"552b7083-6004-4ae7-bfd6-fc539f5c4d48","colab":{"base_uri":"https://localhost:8080/","height":282}},"source":["# Data Visualization\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","# Change this number and re-run the cell to see different image samples!\n","sample_num = 4\n","\n","plt.imshow(X_train[sample_num], cmap=plt.get_cmap('gray'))\n","print(y_train[sample_num])\n","plt.show()"],"execution_count":14,"outputs":[{"output_type":"stream","text":["9\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"MJguwQZZveKN"},"source":["## Step 2: Data Preprocessing\n","\n","* **Flatten** the 28 x 28 2D images into 784-dimensional column vectors. Each pixel will then correspond to one neuron in the 784-dimensional input layer of our neural network.\n","* **Normalize** the pixel values from 0-255 to 0-1. We can do this by simply dividing each of the 0-255 greyscale values by 255. Neural networks typically like to work with smaller values, so this normalization is a pretty common first step in most deep learning tasks.\n","* **Categorize** the outputs into 10-dimensional \"one-hot\" vectors. The MNIST dataset originally contains actual numerical labels for each image (e.g. 1, 2, ...), but remember that our neural network outputs 10 distinct values (one for each digit) -- not just the digit number itself. We want our training labels to match up with our neural network output. These categorized vectors contain all 0's, except a 1 in the location indicating which digit the image corresponds to."]},{"cell_type":"code","metadata":{"id":"cPLgz20yveKO","nbpresent":{"id":"f8dd8606-82f9-4d0c-a62b-45beb371eddc"},"executionInfo":{"status":"ok","timestamp":1601338453751,"user_tz":240,"elapsed":768,"user":{"displayName":"Philip Chang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEO7uNrPZ-ihF9DtyUuEYLoozRGFu5MCZrvu58=s64","userId":"11678586773252254122"}}},"source":["# Flatten 28*28 images to a 784 vector for each image\n","\n","num_pixels = X_train.shape[1] * X_train.shape[2] # 28 * 28 = 784\n","X_train_flattened = X_train.reshape(X_train.shape[0], num_pixels).astype('float32') # new shape: 60,000 x 784\n","X_test_flattened = X_test.reshape(X_test.shape[0], num_pixels).astype('float32') # new shape: 10,000 x 784"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"R5_qiOgWveKQ","nbpresent":{"id":"23cd5489-7e90-47a1-aba3-2a802d1075ac"},"executionInfo":{"status":"ok","timestamp":1601338547806,"user_tz":240,"elapsed":505,"user":{"displayName":"Philip Chang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEO7uNrPZ-ihF9DtyUuEYLoozRGFu5MCZrvu58=s64","userId":"11678586773252254122"}}},"source":["# TODO Normalize pixel values for both train and test sets to between 0-1 (2 lines). Remember, pixel values come within [0,255]\n","X_train_flattened /= 255\n","X_test_flattened /= 255\n"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"OIiRSpZxveKS","nbpresent":{"id":"e11182b1-7e19-4c34-be1e-b1c71179f014"},"executionInfo":{"status":"ok","timestamp":1601338780572,"user_tz":240,"elapsed":540,"user":{"displayName":"Philip Chang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEO7uNrPZ-ihF9DtyUuEYLoozRGFu5MCZrvu58=s64","userId":"11678586773252254122"}},"outputId":"a29a69d8-545a-4320-aa70-bc6668740d43","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Categorize the outputs (\"one-hot\" vectors)    (TODO: 2 lines, fill in the blanks)\n","import tensorflow as tf\n","from tensorflow.keras.utils import to_categorical   # <----- hint: use this \n","\n","# \"one-hot\" encode the training set labels\n","y_train_categorical = to_categorical(y_train, num_classes = 10)\n","# \"one-hot\" encode the test set labels\n","y_test_categorical = to_categorical(y_test, num_classes = 10)\n","\n","# What does the first label look like before and after one-hot encoding?\n","print(y_train[0], y_train_categorical[0])"],"execution_count":25,"outputs":[{"output_type":"stream","text":["5 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"D79_gwvlveKU"},"source":["## Step 3: Create Neural Network Model\n","\n","1. **Initialize** the network, add desired layers. The settings we decide to use, e.g. number of layers, number of neurons per layer, are called **hyperparameters**, and have to be tuned by hand, rather than learned via gradient descent.\n","2. **Compile** the network to get ready for training. This tells the network what cost/loss function to use (\"cost\" and \"loss\" are used interchangeably), and what type of gradient descent to use.\n","3. **Training** the network, using the training images. This actually feeds the training data into the network, and uses gradient descent and backpropagation to adjust the network's weights in order to minimize the cost function.\n","\n","**Workshop [Slides](https://docs.google.com/presentation/d/1BIn3bbdcMxGYzttXZsx82L0tMlyDLFLcMVEjn5o-yyk/edit?usp=sharing)**\n","\n","**Keras Resources**:\n","* [Getting Started](https://keras.io/) \n","* Sequential Model [Overview](https://keras.io/getting-started/sequential-model-guide/)\n","* Sequential Model [Documentation](https://keras.io/models/sequential/) \n","* [Core Layers](https://keras.io/layers/core/) \n","* [Activation Functions](https://keras.io/activations/)\n","* [Cost/Loss Functions](https://keras.io/losses)\n","* [Optimizers](https://keras.io/optimizers) \n","\n"]},{"cell_type":"code","metadata":{"id":"3dhgvgeHveKU","nbpresent":{"id":"81b9fc81-511c-4d2d-be23-883d0009bc74"},"executionInfo":{"status":"ok","timestamp":1601340099365,"user_tz":240,"elapsed":535,"user":{"displayName":"Philip Chang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEO7uNrPZ-ihF9DtyUuEYLoozRGFu5MCZrvu58=s64","userId":"11678586773252254122"}},"outputId":"9b68cb45-edc6-4e89-e90a-dfd7aa3f7921","colab":{"base_uri":"https://localhost:8080/","height":255}},"source":["# 1 -- Network Initialization (TODO 3 lines)\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","\n","# Initialize a simple 'blank-slate' sequential neural network model\n","model = Sequential() \n","\n","# TODO Add hidden layer 1: __ neurons (up to you), 'relu' activation \n","model.add(Dense(units = 128, activation = 'relu', input_dim = 784))\n","# TODO Add hidden layer 2: __ neurons (up to you), 'relu' activation\n","model.add(Dense(units = 64, activation = 'relu'))\n","# TODO Add output layer: ? neurons (one for each class), 'softmax' activation\n","model.add(Dense(units = 10, activation = 'softmax'))\n","\n","# Print a summary of what you just created\n","model.summary() "],"execution_count":36,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_3 (Dense)              (None, 128)               100480    \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 64)                8256      \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 10)                650       \n","=================================================================\n","Total params: 109,386\n","Trainable params: 109,386\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"T4M0QIT3veKX","nbpresent":{"id":"bf842b6a-20db-42f4-9333-b1e30857e725"},"executionInfo":{"status":"ok","timestamp":1601340222217,"user_tz":240,"elapsed":558,"user":{"displayName":"Philip Chang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEO7uNrPZ-ihF9DtyUuEYLoozRGFu5MCZrvu58=s64","userId":"11678586773252254122"}}},"source":["# 2 -- Network Compilation (TODO 1 line)\n","\n","# TODO Compile. Loss function: categorical crossentropy. Optimizer: stochastic gradient descent (SGD). Metrics: 'accuracy'\n","model.compile(loss = 'categorical_crossentropy', optimizer = 'sgd', metrics = ['accuracy'])\n"],"execution_count":41,"outputs":[]},{"cell_type":"code","metadata":{"id":"DaP6NX1SveKZ","executionInfo":{"status":"ok","timestamp":1601340241437,"user_tz":240,"elapsed":17971,"user":{"displayName":"Philip Chang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEO7uNrPZ-ihF9DtyUuEYLoozRGFu5MCZrvu58=s64","userId":"11678586773252254122"}},"outputId":"c4653af0-754e-460c-efda-d4150b70313f","colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["# 3 -- Network Training (TODO 1 line)\n","\n","# TODO Fit the model to the data. Number of epochs: ___ (up to you). Batch size: ___ (up to you, conventionally a power of 2)\n","model.fit(X_train_flattened, y_train_categorical, epochs = 5, batch_size = 32)"],"execution_count":42,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n","1875/1875 [==============================] - 3s 2ms/step - loss: 0.6154 - accuracy: 0.8346\n","Epoch 2/5\n","1875/1875 [==============================] - 3s 2ms/step - loss: 0.2905 - accuracy: 0.9171\n","Epoch 3/5\n","1875/1875 [==============================] - 3s 2ms/step - loss: 0.2402 - accuracy: 0.9309\n","Epoch 4/5\n","1875/1875 [==============================] - 3s 2ms/step - loss: 0.2069 - accuracy: 0.9413\n","Epoch 5/5\n","1875/1875 [==============================] - 3s 2ms/step - loss: 0.1826 - accuracy: 0.9478\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fde5c6af780>"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"markdown","metadata":{"id":"7426fdCMveKb"},"source":["## Step 4: Evaluation & Predictions"]},{"cell_type":"code","metadata":{"id":"WFftjUuNveKc","nbpresent":{"id":"0864543a-2392-4ae5-bbdd-375e934184f4"},"executionInfo":{"status":"ok","timestamp":1601340406645,"user_tz":240,"elapsed":749,"user":{"displayName":"Philip Chang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEO7uNrPZ-ihF9DtyUuEYLoozRGFu5MCZrvu58=s64","userId":"11678586773252254122"}},"outputId":"18abb3a5-8e1b-4c12-b761-645fed8a09f6","colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["# 4 -- Evaluate on the test data! (TODO 1 line + fill in 2 print statements)\n","\n","# TODO Evaluate the model on the test set and \n","#      store the results (loss and metrics) into a variable. Batch size: ___ (up to you, conventionally a power of 2)\n","loss_and_metrics = model.evaluate(X_test_flattened, y_test_categorical, batch_size = 128)\n","\n","# TODO Print your variable (which will be an array, since it contains both loss [0] and metrics [1])\n","print(\"Final test cost/loss: \", loss_and_metrics[0])\n","print(\"Final test accuracy: \",  loss_and_metrics[1])\n"],"execution_count":44,"outputs":[{"output_type":"stream","text":["79/79 [==============================] - 0s 2ms/step - loss: 0.1702 - accuracy: 0.9507\n","Final test cost/loss:  0.1702108085155487\n","Final test accuracy:  0.9506999850273132\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Z7JE7YyYveKf"},"source":["**Final Sanity Check:** Make sure the our neural network's predictions match up with the actual images"]},{"cell_type":"code","metadata":{"id":"OazZ1sGOveKf","nbpresent":{"id":"3cdfe0ff-f08a-4ded-af33-c091211b22a7"},"executionInfo":{"status":"ok","timestamp":1601340493102,"user_tz":240,"elapsed":701,"user":{"displayName":"Philip Chang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEO7uNrPZ-ihF9DtyUuEYLoozRGFu5MCZrvu58=s64","userId":"11678586773252254122"}},"outputId":"34a3c3ad-cc20-4182-f378-4c317a7b21a4","colab":{"base_uri":"https://localhost:8080/","height":333}},"source":["# Pick a random test sample and see what the model predicts! \n","sample_num = 0 \n","\n","import numpy as np\n","\n","test_sample = np.expand_dims(X_test_flattened[sample_num], axis=0) # pick out a one-sample \"batch\" to feed into model\n","predicted_scores = model.predict(test_sample) # outputted probabilities vector\n","print(\"Output vector: \", predicted_scores[0]) # print predicted scores\n","\n","predicted_class = np.argmax(predicted_scores) # pick the class with highest probability --> final prediction\n","print(\"Predicted digit: \", predicted_class) # print predicted classification\n","\n","# Show actual input image\n","plt.imshow(X_test[sample_num], cmap=plt.get_cmap('gray'))\n","plt.show()"],"execution_count":45,"outputs":[{"output_type":"stream","text":["Output vector:  [1.15588286e-04 4.22381788e-07 1.77498814e-03 5.26629062e-03\n"," 1.05564538e-07 1.08427026e-04 5.67536684e-09 9.92511749e-01\n"," 5.55724764e-05 1.66871963e-04]\n","Predicted digit:  7\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"0d8fm_EuveKk"},"source":["## Congrats! You just did deep learning!\n","\n","### Additional Resources:\n","* CAIS++ [Blog](http://caisplusplus.usc.edu/blog/curriculum/lesson4) Posts \n","* [3Blue1Brown](https://www.youtube.com/watch?v=aircAruvnKk) Videos \n","* ML Cheatsheet for [Activation Functions](http://ml-cheatsheet.readthedocs.io/en/latest/activation_functions.html) \n","* ML Cheatsheet for [Cost/Loss Functions](http://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html)\n","* Michael Nielsen [Free Online Book](http://neuralnetworksanddeeplearning.com) "]}]}